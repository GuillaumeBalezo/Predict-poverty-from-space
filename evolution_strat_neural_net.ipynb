{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# resize data\n",
    "x_train = np.reshape(x_train, (60000, 28*28))\n",
    "x_test = np.reshape(x_test, (10000, 28*28))\n",
    "\n",
    "# normalize data\n",
    "x_train= x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# pre-process labels\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(l1, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='sigmoid'))                     \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 208us/step - loss: 2.0737 - acc: 0.5206 - val_loss: 1.7292 - val_acc: 0.8067\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 2s 42us/step - loss: 1.3862 - acc: 0.8006 - val_loss: 1.0278 - val_acc: 0.8650\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.9002 - acc: 0.8403 - val_loss: 0.7007 - val_acc: 0.8858\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.6815 - acc: 0.8611 - val_loss: 0.5494 - val_acc: 0.8938\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.5696 - acc: 0.8733 - val_loss: 0.4657 - val_acc: 0.9020\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.5028 - acc: 0.8805 - val_loss: 0.4128 - val_acc: 0.9080\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.4585 - acc: 0.8859 - val_loss: 0.3778 - val_acc: 0.9122\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.4273 - acc: 0.8903 - val_loss: 0.3520 - val_acc: 0.9163\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.4036 - acc: 0.8942 - val_loss: 0.3328 - val_acc: 0.9178\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.3850 - acc: 0.8977 - val_loss: 0.3175 - val_acc: 0.9203\n"
     ]
    }
   ],
   "source": [
    "# Set training hyperparameters\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Train the network\n",
    "history_train = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203333333333333\n"
     ]
    }
   ],
   "source": [
    "print(history_train.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(l1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(l1), activation='sigmoid', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    history_train = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.10, verbose=False)\n",
    "    return history_train.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.20906625 38.70650577 44.28297119 57.87482247 44.66936891 44.18674641\n",
      " 52.06536467 51.0802398 ]\n",
      "[0.7468333333333333, 0.7705, 0.7861666666666667, 0.7808333333333334, 0.7765, 0.8036666666666666, 0.785, 0.791]\n",
      "39.957786011168814 35.413479540768265\n",
      "[36.93957403 45.34386325 50.47220547 41.6040618  42.35794757 48.0884464\n",
      " 33.9388136  42.71605071]\n",
      "[0.728, 0.782, 0.8016666666666666, 0.7908333333333334, 0.7758333333333334, 0.7411666666666666, 0.6865, 0.7853333333333333]\n",
      "35.4391938109973 22.668816261634596\n",
      "[41.22331464 33.47486426 36.91903082 27.80888444 40.46431313 28.93933341\n",
      " 30.74339488 34.65717464]\n",
      "[0.7603333333333333, 0.77, 0.772, 0.7518333333333334, 0.788, 0.7845, 0.7038333333333333, 0.751]\n",
      "32.70028475956641 11.33104078736714\n",
      "[28.80192049 30.16879621 29.23167493 30.35716054 34.29159078 34.81186141\n",
      " 38.10692855 29.44600782]\n",
      "[0.8005, 0.712, 0.7425, 0.76, 0.794, 0.8075, 0.7801666666666667, 0.7345]\n",
      "29.807402014419225 8.49937633849999\n",
      "[24.93195235 26.78689031 30.30344418 28.77142635 32.439264   28.26201592\n",
      " 30.52324732 26.92068996]\n",
      "[0.7263333333333334, 0.745, 0.7258333333333333, 0.7686666666666667, 0.7765, 0.7555, 0.7668333333333334, 0.7406666666666667]\n",
      "27.617698266911084 12.008033622065076\n",
      "[30.22057496 31.15050406 30.27883853 20.7098047  26.06170838 21.42159063\n",
      " 31.23675544 29.79731189]\n",
      "[0.7558333333333334, 0.7746666666666666, 0.7091666666666666, 0.6956666666666667, 0.7736666666666666, 0.7095, 0.7391666666666666, 0.7665]\n",
      "25.49432161820703 27.400330510154024\n",
      "[25.38466568 22.49252066 20.20452959 22.86143841 20.22393623 23.2346335\n",
      " 29.53913511 28.83026477]\n",
      "[0.754, 0.7228333333333333, 0.6943333333333334, 0.6653333333333333, 0.7086666666666667, 0.7595, 0.765, 0.7601666666666667]\n",
      "21.532983999554904 17.45698684491793\n",
      "[19.94632653 19.19858592 19.73190527 21.56906041 22.48215232 20.82716931\n",
      " 19.91698273 21.92833361]\n",
      "[0.6873333333333334, 0.608, 0.6838333333333333, 0.6603333333333333, 0.7425, 0.7275, 0.7578333333333334, 0.7338333333333333]\n",
      "20.383823163318507 2.7253579558470875\n",
      "[21.23213273 23.43005527 20.66255159 20.6354534  23.321956   20.00804489\n",
      " 19.84015247 21.53047008]\n",
      "[0.7153333333333334, 0.7706666666666667, 0.5773333333333334, 0.6406666666666667, 0.7096666666666667, 0.7496666666666667, 0.6623333333333333, 0.6866666666666666]\n",
      "20.649002494292468 0.07050365552779411\n",
      "[20.53662156 20.52225254 20.4340351  20.23234259 20.32456142 20.76222797\n",
      " 20.51842066 20.07495538]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-85cc52cd134c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfitness_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-85cc52cd134c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfitness_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ce5d8a6e3fa4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(l1)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhistory_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Predict-poverty/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/Predict-poverty/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Predict-poverty/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Predict-poverty/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_pop = 50\n",
    "prop_chosen = 0.25\n",
    "nb_epochs = 10\n",
    "\n",
    "x0 = np.random.uniform(0, 100)\n",
    "mu0, sig0 = x0, 100\n",
    "x_list = []\n",
    "x_list.append(mu0)\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    gen0 = np.random.randn(nb_pop)*np.sqrt(sig0) + mu0\n",
    "    print(gen0)\n",
    "    \n",
    "    fitness_scores = [model(g) for g in gen0]\n",
    "    print(fitness_scores)\n",
    "    \n",
    "    # Get best individuals\n",
    "    res = sorted(zip(fitness_scores, gen0))\n",
    "    nb_survivor = int(prop_chosen * len(gen0))\n",
    "    res = res[:nb_survivor]\n",
    "    res = np.array(res)\n",
    "    x0_best = res[:, 1]\n",
    "    \n",
    "    # Update mean and variance of the next generation\n",
    "    tmp = mu0\n",
    "    mu0 = np.mean(x0_best)\n",
    "    sig0 = np.sum((x0_best - tmp)**2) / nb_survivor\n",
    "    print(mu0, sig0)\n",
    "    x_list.append(mu0)\n",
    "\"\"\"\n",
    "mu0, sig0 = int(x0), 1\n",
    "x_list = []\n",
    "x_list.append(mu0)\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    # Generate population\n",
    "    gen0 = np.random.randn(nb_pop)*np.sqrt(sig0) + mu0\n",
    "    \n",
    "    # Evaluate population\n",
    "    fitness_scores = [model(g) for g in gen0]\n",
    "    \n",
    "    # Get best individuals\n",
    "    res = sorted(zip(fitness_scores, gen0))\n",
    "    nb_survivor = int(prop_chosen * len(gen0))\n",
    "    res = res[:nb_survivor]\n",
    "    res = np.array(res)\n",
    "    x0_best = res[:, 1]\n",
    "    \n",
    "    # Update mean and variance of the next generation\n",
    "    tmp = mu0\n",
    "    mu0 = np.mean(x0_best)\n",
    "    sig0 = np.sum((x0_best - tmp)**2) / nb_survivor\n",
    "    x_list.append(mu0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5 Predict-poverty",
   "language": "python",
   "name": "predict-poverty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
